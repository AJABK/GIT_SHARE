import java.io.BufferedReader;
import java.io.BufferedWriter;
import java.io.File;
import java.io.FileOutputStream;
import java.io.FileReader;
import java.io.IOException;
import java.io.InputStreamReader;
import java.io.OutputStreamWriter;
import java.util.ArrayList;
import java.util.Collections;
import java.util.HashMap;
import java.util.Iterator;
import java.util.LinkedHashMap;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;

import org.apache.commons.lang.StringUtils;
import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.analysis.core.SimpleAnalyzer;
import org.apache.lucene.document.Document;
import org.apache.lucene.document.Field;
import org.apache.lucene.document.StringField;
import org.apache.lucene.document.TextField;
import org.apache.lucene.index.DirectoryReader;
import org.apache.lucene.index.Fields;
import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.IndexWriter;
import org.apache.lucene.index.IndexWriterConfig;
import org.apache.lucene.index.MultiFields;
import org.apache.lucene.index.Term;
import org.apache.lucene.index.Terms;
import org.apache.lucene.index.TermsEnum;
import org.apache.lucene.queryparser.classic.QueryParser;
import org.apache.lucene.search.IndexSearcher;
import org.apache.lucene.search.Query;
import org.apache.lucene.search.ScoreDoc;
import org.apache.lucene.search.TopScoreDocCollector;
import org.apache.lucene.store.FSDirectory;
import org.apache.lucene.util.BytesRef;
import org.apache.lucene.util.Version;

/**
 * To create Apache Lucene index in a folder and add files into this index based
 * on the input of the user.
 */
public class HW4 {
    private static Analyzer analyzer = new StandardAnalyzer(Version.LUCENE_47);
    //private static Analyzer sAnalyzer = new SimpleAnalyzer(Version.LUCENE_47);

    private IndexWriter writer;
    private ArrayList<File> queue = new ArrayList<File>();

    public static void main(String[] args) throws IOException {
	System.out
		.println("Enter the FULL path where the index will be created: (e.g. /Usr/index or c:\\temp\\index)");

	String indexLocation = null;
	BufferedReader br = new BufferedReader(new InputStreamReader(System.in));
	String s = br.readLine();

	HW4 indexer = null;
	try {
	    indexLocation = s;
	    indexer = new HW4(s);
	} catch (Exception ex) {
	    System.out.println("Cannot create index..." + ex.getMessage());
	    System.exit(-1);
	}

	// ===================================================
	// read input from user until he enters q for quit
	// ===================================================
	while (!s.equalsIgnoreCase("q")) {
	    try {
		System.out
			.println("Enter the FULL path to add into the index (q=quit): (e.g. /home/mydir/docs or c:\\Users\\mydir\\docs)");
		System.out
			.println("[Acceptable file types: .xml, .html, .html, .txt]");
		s = br.readLine();
		if (s.equalsIgnoreCase("q")) {
		    break;
		}
		
		// try to add file into the index
		indexer.indexFileOrDirectory(s);
	    } catch (Exception e) {
		System.out.println("Error indexing " + s + " : "
			+ e.getMessage());
	    }
	}
	
	// ===================================================
	// after adding, we always have to call the
	// closeIndex, otherwise the index is not created
	// ===================================================
	indexer.closeIndex();

	// ===================================================
	// create the term -> frequency pair for entire
	// collection
	// ===================================================
		s = "";
	    try {
		System.out
			.println("Enter the FULL path to add term frequencies (q=quit): (e.g. /home/mydir/docs or c:\\Users\\mydir\\docs)");
		s = br.readLine();
		// exit if pressed "q"
		if (!s.equalsIgnoreCase("q")) {
			IndexReader iReader = DirectoryReader.open(FSDirectory.open(new File(
					indexLocation)));
			Fields fields = MultiFields.getFields(iReader);
			// map for storing term frequency
			Map<String, Long> termFreqMap = new HashMap<>();
	        for (String field : fields) {
	        	// take the content index only
	        	if (!field.equals("contents")) {
	        		continue;
	        	}
	            Terms terms = fields.terms(field);
	            TermsEnum termsEnum = terms.iterator(null);
	            BytesRef b;
	            // iterate over all terms
	            while ((b = termsEnum.next()) != null) {
	            	// get UTF-8 from the BytesRef
	            	String term = b.utf8ToString();
	            	// commented to account all index terms
	            	/*if (StringUtils.isNumeric(term) || term.equals("pre") || term.equals("html")) {
						continue;
					}*/
	            	Term termInstance = new Term("contents", term);
	        		long termFreq = iReader.totalTermFreq(termInstance);
	        		if (termFreqMap.containsKey(term)) {
	        			termFreq += termFreqMap.get(term);
	        		}
	        		termFreqMap.put(term, termFreq);        		
	            }
	        }
	        
			// sort the terms by frequency
			List<Map.Entry<String, Long>> entries = new LinkedList<Map.Entry<String, Long>>(termFreqMap.entrySet());
			Collections.sort(entries, new HW4Comparator());
			
			Map<String, Long> sortedTermFreq = new LinkedHashMap<String, Long>();
			// add all entries into sorted linked hashmap
			for (Map.Entry<String, Long> entry : entries) {
				sortedTermFreq.put(entry.getKey(), entry.getValue());
			}
			// write all terms into file
			writeTermFreq(s, sortedTermFreq);
		}
		
	    } catch (Exception e) {
		System.out.println("Error while getting term -> freq " + s + " : "
			+ e.getMessage());
	    }
	
	
	// =========================================================
	// Now search
	// =========================================================
	IndexReader reader = DirectoryReader.open(FSDirectory.open(new File(
		indexLocation)));
	IndexSearcher searcher = new IndexSearcher(reader);

	s = "";
	while (!s.equalsIgnoreCase("q")) {
	    try {
		System.out.println("Enter the search query (q=quit):");
		s = br.readLine();
		if (s.equalsIgnoreCase("q")) {
		    break;
		}

		TopScoreDocCollector collector = TopScoreDocCollector.create(3204, true);
		Query q = new QueryParser(Version.LUCENE_47, "contents",
				sAnalyzer).parse(s);
		searcher.search(q, collector);
		ScoreDoc[] hits = collector.topDocs().scoreDocs;

		// 4. display results
		System.out.println("Found " + hits.length + " hits.");
		for (int i = 0; i < hits.length; ++i) {
		    int docId = hits[i].doc;
		    Document d = searcher.doc(docId);
		    System.out.println((i + 1) + ". " + d.get("path")
			    + " score=" + hits[i].score);
		}
		// 5. term stats --> watch out for which "version" of the term
		// must be checked here instead!
		Term termInstance = new Term("contents", s);
		long termFreq = reader.totalTermFreq(termInstance);
		long docCount = reader.docFreq(termInstance);
		System.out.println(s + " Term Frequency " + termFreq
			+ " - Document Frequency " + docCount);

	    } catch (Exception e) {
		System.out.println("Error searching " + s + " : "
			+ e.getMessage());
		break;
	    }

	}

    }

    /**
     * Constructor
     * 
     * @param indexDir
     *            the name of the folder in which the index should be created
     * @throws java.io.IOException
     *             when exception creating index.
     */
    HW4(String indexDir) throws IOException {

	FSDirectory dir = FSDirectory.open(new File(indexDir));

	IndexWriterConfig config = new IndexWriterConfig(Version.LUCENE_47,
			sAnalyzer);

	writer = new IndexWriter(dir, config);
    }

    /**
     * Indexes a file or directory
     * 
     * @param fileName
     *            the name of a text file or a folder we wish to add to the
     *            index
     * @throws java.io.IOException
     *             when exception
     */
    public void indexFileOrDirectory(String fileName) throws IOException {
	// ===================================================
	// gets the list of files in a folder (if user has submitted
	// the name of a folder) or gets a single file name (is user
	// has submitted only the file name)
	// ===================================================
	addFiles(new File(fileName));

	int originalNumDocs = writer.numDocs();
	for (File f : queue) {
	    FileReader fr = null;
	    try {
		Document doc = new Document();

		// ===================================================
		// add contents of file
		// ===================================================
		fr = new FileReader(f);
		doc.add(new TextField("contents", fr));
		doc.add(new StringField("path", f.getPath(), Field.Store.YES));
		doc.add(new StringField("filename", f.getName(),
			Field.Store.YES));

		writer.addDocument(doc);
		System.out.println("Added: " + f);
	    } catch (Exception e) {
		System.out.println("Could not add: " + f);
	    } finally {
		fr.close();
	    }
	}

	int newNumDocs = writer.numDocs();
	System.out.println("");
	System.out.println("************************");
	System.out
		.println((newNumDocs - originalNumDocs) + " documents added.");
	System.out.println("************************");

	queue.clear();
    }

    private void addFiles(File file) {

	if (!file.exists()) {
	    System.out.println(file + " does not exist.");
	}
	if (file.isDirectory()) {
	    for (File f : file.listFiles()) {
		addFiles(f);
	    }
	} else {
	    String filename = file.getName().toLowerCase();
	    // ===================================================
	    // Only index text files
	    // ===================================================
	    if (filename.endsWith(".htm") || filename.endsWith(".html")
		    || filename.endsWith(".xml") || filename.endsWith(".txt")) {
		queue.add(file);
	    } else {
		System.out.println("Skipped " + filename);
	    }
	}
    }
    
    /**
     * 
     * @param path
     * @param sortedTermFreq
     */
    public static void writeTermFreq(String path, Map<String, Long> sortedTermFreq) {
    	try {
			// output stream for result file
			FileOutputStream output = null;
			// Buffer writer for writing the result file
			BufferedWriter writer = null;
			int termCount = 1;
			// result file
			File result = new File(path + "\\sorted_term_freq.txt");
			// open the output stream for writing ranking result
			if (output == null) {
				output = new FileOutputStream(result);
			}
			// get buffer writer for writing the file
			writer = new BufferedWriter(new OutputStreamWriter(output));
			// iterator for getting ranked documents for each query
			Iterator<String> it = sortedTermFreq.keySet().iterator();
			// iterate over rank results for each query
			while (it.hasNext()) {
				String term = it.next();
				writer.write((termCount++) + "." + " (" + term + ", " + sortedTermFreq.get(term)+ ")");
				writer.newLine();
			}
			writer.close();

		} catch (IOException e) {
			e.printStackTrace();
		}
    }

    /**
     * Close the index.
     * 
     * @throws java.io.IOException
     *             when exception closing
     */
    public void closeIndex() throws IOException {
	writer.close();
    }
}